{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import re, pickle, betacode.conv\n",
    "from os import path\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "from itertools import takewhile\n",
    "from ordered_set import OrderedSet\n",
    "from unicodedata import category, normalize\n",
    "from collections import OrderedDict, namedtuple\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Text Fabric imports\n",
    "from tf.fabric import Fabric, Timestamp\n",
    "from tf.convert.walker import CV\n",
    "\n",
    "# Local imports ##TODO! Cleanup...\n",
    "from helpertools.lemmatizer import lemmatize\n",
    "from helpertools.unicodetricks import *\n",
    "from helpertools.xmlparser import xmlSplitter, dataParser, metadataReader, attribsAnalysis #, lenAttribsDict, sectionElems\n",
    "from tf_config import langsettings\n",
    "from data.tlge_metadata import tlge_metadata\n",
    "from data.attrib_errors import error_dict\n",
    "from convertor_metadata import convertor_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conversion:\n",
    "    def __init__(self, data, lang='generic', typ=False, **kwargs):\n",
    "        self.data = data\n",
    "        self.lang = lang\n",
    "        self.typ  = typ\n",
    "        \n",
    "        # Set all keys in langsettings (tf_config.py) as class attributes\n",
    "        # NB Make sure that metadata are uploaded to langsettings somewhere in the process!\n",
    "        for setting, value in kwargs[self.lang].items():\n",
    "            setattr(self, setting, value)\n",
    "            \n",
    "        # Variables used in processing\n",
    "        self.res_text = None\n",
    "\n",
    "        self.tlg_head = False\n",
    "        \n",
    "        # Add token features to nonIntFeatures set\n",
    "        try:\n",
    "            self.nonIntFeatures.update(self.token_out)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        print('The current class attributes are:')\n",
    "        for key, value in self.__dict__.items():\n",
    "            print(f'{key:<20} = {value}')\n",
    "\n",
    "            \n",
    "    def process_text(self, text):\n",
    "        text_output = []\n",
    "        #Check and convert Greek betacode\n",
    "        if self.lang == 'greek':\n",
    "            try:\n",
    "                text.encode('ascii')\n",
    "                text = normalize(udnorm, betacode.conv.beta_to_uni(text))\n",
    "            except UnicodeEncodeError:\n",
    "                text = normalize(udnorm, text)\n",
    "                \n",
    "        #Handle wordbreaks\n",
    "        if self.res_text != None:\n",
    "            text, self.res_text = self.res_text + text, None\n",
    "        if text.endswith(self.non_splitters):\n",
    "            text, self.res_text = text.rstrip(''.join(self.non_splitters)).rsplit(' ', 1)\n",
    "    \n",
    "        #Process text\n",
    "        for token in self.tokenizer(text, **self.tokenizer_args):\n",
    "            \n",
    "            self.replace_func(t)\n",
    "            \n",
    "            token_out = {}\n",
    "            if not token:\n",
    "                continue\n",
    "            \n",
    "            # self.token_out defines the structure of token e.g. Greek = (pre, word, post)\n",
    "            for i, part in enumerate(self.token_out):\n",
    "                if self.token_out[part]['text_format'] = True:\n",
    "                    for form in self.text_formats:\n",
    "                        token_out[form] = form.function(token[i])\n",
    "                else:\n",
    "                    token_out[part] = token[i]\n",
    "            text_output.append(token_out)\n",
    "                \n",
    "            \n",
    "                \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Csv2tf(Conversion):\n",
    "    def __init__(self, data, lang='generic', header=False, **kwargs):\n",
    "        super().__init__(self, data, lang, **kwargs)\n",
    "        self.header   = self.get_header(header)\n",
    "        self.sections = self.header if header == True \\\n",
    "                                 else ( list(filter(None, self.metadata['citation_scheme'].split('/'))) \\\n",
    "                                       if 'citation_scheme' in self.metadata \\\n",
    "                                 else list(filter(None, input(\"No header data could be found; please enter an appropriate header: \").split())) )\n",
    "        self.structs  = list(tuple(self.header) + tuple(self.struct_counter))\n",
    "        self.otext = {\n",
    "            **{k: v['format'] for k, v in self.text_formats.items()}, \\\n",
    "            **{'sectionTypes': f'{\",\".join(self.sections[:2] + [self.sections[-1]] if len(self.sections) > 2 else self.sections)}'}, \\\n",
    "            **{'sectionFeatures': f'{\",\".join(self.sections[:2] + [self.sections[-1]] if len(self.sections) > 2 else self.sections)}'}, \\\n",
    "            **{'structureTypes': f'_book,{\",\".join(self.structs)}'}, \\\n",
    "            **{'structureFeatures': f'_book,{\",\".join(self.structs)}'}\n",
    "        }\n",
    "        self.featureMeta = {v['name']: {'description': v['metadata']} \\\n",
    "                            for k, v in self.text_formats.items()}\n",
    "\n",
    "        \n",
    "    def get_header(head):\n",
    "        \n",
    "        def check_header(measure, typed_input):\n",
    "            if len(typed_input) == measure:\n",
    "                print('header successfully entered!')\n",
    "                return typed_input\n",
    "            else:\n",
    "                print('The inputed number of header titles is {len(typed_input)}, while it should be {measure}')\n",
    "                typed_input = list(filter(None, input(\"No header data could be found; please enter an appropriate header: \").split()))\n",
    "                check_header(measure, typed_input)\n",
    "        \n",
    "        levels = len(self.data[0].split('\\t'))\n",
    "        \n",
    "        if head == False:\n",
    "            levels = len(self.data[0].split('\\t'))\n",
    "            if levels == 0:\n",
    "                header = []\n",
    "            else:\n",
    "                header = check_header(levels, list(filter(None, input(\"No header data could be found; please enter an appropriate header: \").split())))\n",
    "        else:\n",
    "            if isinstance(head, (list, tuple)):\n",
    "                header = check_header()\n",
    "                header = head\n",
    "            else:\n",
    "                header = self.data[0].split('\\t')[:-1]\n",
    "                self.data = self.data[1:]\n",
    "        return header\n",
    "        \n",
    "    \n",
    "    def director(self, cv):\n",
    "        nonIntFeatures = self.nonIntFeatures\n",
    "        counter        = self.struct_counter\n",
    "        udnorm         = self.udnorm\n",
    "        \n",
    "        linked_features_dict = {}\n",
    "        lemma_counter        = [0, 0]\n",
    "        cur                  = {}\n",
    "        \n",
    "        #Designate bookname and start first node assignment\n",
    "        cur['_book'] = cv.node('_book')\n",
    "        cv.feature(cur['_book'], _book=self.metadata['title'])\n",
    "        cv.meta('_book', description=self.metadata['title_full'])\n",
    "        nonIntFeatures.add('_book')\n",
    "        \n",
    "        #Declaration of global variables used in the process_text() method!\n",
    "        tlg_head = False\n",
    "        res_text = None\n",
    "        \n",
    "        for line in self.data:\n",
    "            splitline = line.split('\\t')\n",
    "            ref = splitline[:-1]\n",
    "            text = splitline[-1].strip()\n",
    "        \n",
    "            # Handle sectioning\n",
    "            ind = 0\n",
    "            for sec in self.sections:\n",
    "                num = ind + 1\n",
    "                if sec in cur and cv.active(cur[sec]):\n",
    "                    cur_sec = cv.get(sec, cur[sec])\n",
    "                    new_sec = ref[ind]\n",
    "                    if not cur_sec == new_sec:\n",
    "                        for s in self.sections[:ind:-1]:\n",
    "                            cv.terminate(cur[s])\n",
    "                        cv.terminate(cur[sec])\n",
    "                        cur[sec] = cv.node(sec)\n",
    "                        cv.feature(cur[sec], **{sec: ref[ind]})\n",
    "                        cv.meta(sec, description=f'structure feature of the {num}{\"st\" if num == 1 else \"\"}{\"nd\" if num == 2 else \"\"}{\"rd\" if num == 3 else \"\"}{\"th\" if num > 3 else \"\"} level',)\n",
    "                else:\n",
    "                    cur[sec] = cv.node(sec)\n",
    "                    cv.feature(cur[sec], **{sec: ref[ind]})\n",
    "                    cv.meta(sec, description=f'structure feature of the {num}{\"st\" if num == 1 else \"\"}{\"nd\" if num == 2 else \"\"}{\"rd\" if num == 3 else \"\"}{\"th\" if num > 3 else \"\"} level',)\n",
    "                if not ref[ind].isdigit():\n",
    "                    nonIntFeatures.add(sec)\n",
    "                ind +=1\n",
    "        \n",
    "            # Handle TLG heads {head words}\n",
    "            if self.typ == 'tlge':\n",
    "                if self.head_signs['start'] & ( set(pre) | set(post) ):\n",
    "                    self.tlg_head = True\n",
    "                if self.head_signs['stop'] & ( set(pre) | set(post) ):\n",
    "                    self.tlg_head = False\n",
    "                    \n",
    "            # TODO: Check for res_text first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tlg2tf(Xml2tf):\n",
    "    def __init__():\n",
    "        super().__init__(self, data, lang='greek', **kwargs)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xml2tf(Conversion):\n",
    "    def __init__(self, data, lang='generic', **kwargs):\n",
    "        super().__init__(self, data, lang, **kwargs)\n",
    "\n",
    "    def director(self, cv):\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(input_path, output_path, lang='generic', typ=False, **kwargs):\n",
    "    # For how to change the kwargs arguments: https://stackoverflow.com/questions/44784577/in-method-call-args-how-to-override-keyword-argument-of-unpacked-dict\n",
    "    \n",
    "    \n",
    "    if typ == 'tlge':\n",
    "        kwargs['head_signs'] =  {'start': '{',\n",
    "                                 'stop': '}',}\n",
    "        \n",
    "    #Check for original or preprocessed tlg-E files\n",
    "    \n",
    "    elif typ == 'mss':\n",
    "        pass\n",
    "    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
