{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tfbuilder tutorial\n",
    "The whole machinery of tfbuilder can be used by importing the convert function from the tfbuilder library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from tfbuilder import convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### arguments `convert()`\n",
    "    input_path      = folder path in which the files to be converted are\n",
    "    output_path     = folder path to which all tf-modules are to be written\n",
    "    file_elem       = define necessary part in source filename\n",
    "    tlg_out         = `True` if one wants TLG codes as folder names `False` if folder names from metadata\n",
    "    ignore_empty    = `True` if source files that don't produce slot numbers need to be ignored\n",
    "    generic         = Generic metadata to be present in every tf-file to be produced\n",
    "    lang            = language (referring to languages available in `langsettings`)\n",
    "    typ             = subtype of a language, if special behavious is required, like `tlge` (tlg-e cdrom)\n",
    "    header          = if True, the convertor expects csv-files to have a header\n",
    "    version         = version number to be assigned to the tf-module\n",
    "    langsettings    = langsettings to be imported; usually, this is the langsettings provided by tfbuilder\n",
    "    multiprocessing = False --> no multiprocessing\n",
    "                    = True  --> active multiprocessing; authomatic assignment of number of processor threads\n",
    "                    = int   --> manual assingment of number of processor threads\n",
    "    chunksize       = number of files to be assigned to each thread each cycle\n",
    "    silent          = if True, all TF-messages are suppressed\n",
    "    \n",
    "#### remarks `generic` and `langsettings`:\n",
    "Both are accessible and changeable in tf_config.py. However, one is able to pass his/her own settings (=dictionary) to the convert function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert('/media/ernstboogert/ResearchDat/sources',\n",
    "convert(path.expanduser('~/github/pthu/sources/greek_sources/canonical-greekLit/data/tlg2046'),\n",
    "#         path.expanduser('~/github/pthu/OUT'),\n",
    "        '/media/ernstboogert/ResearchDat/TF_dissertation/Perseus',\n",
    "        ignore_empty=False,\n",
    "        tlg_out=False,\n",
    "        lang='greek', \n",
    "        typ=False, \n",
    "        header=False,\n",
    "        multiprocessing=False,\n",
    "        chunksize=1,\n",
    "        silent=False,\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "convert(path.expanduser('~/github/pthu/sources/greek_sources'),\n",
    "#         path.expanduser('~/github/pthu/OUT'),\n",
    "        '/media/ernstboogert/ResearchDat/TF_dissertation/Perseus/12032020',\n",
    "        file_elem='grc',\n",
    "        ignore_empty=False,\n",
    "        tlg_out=True,\n",
    "        lang='greek', \n",
    "        typ=False, \n",
    "        header=False,\n",
    "        multiprocessing=False,\n",
    "        chunksize=10,\n",
    "        silent=False,\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert('/media/ernstboogert/ResearchDat/TLG_E/tsv',\n",
    "        '/media/ernstboogert/ResearchDat/TF_dissertation/TLG_E',\n",
    "        file_elem='tlg',\n",
    "        ignore_empty=True,\n",
    "        tlg_out=True,\n",
    "        lang='greek', \n",
    "        typ='tlge', \n",
    "        header=True,\n",
    "        multiprocessing=False,\n",
    "        chunksize=10,\n",
    "        silent=True,\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "header = None\n",
    "\n",
    "# import csv\n",
    "# sniffer = csv.Sniffer()\n",
    "# sample_bytes = 32\n",
    "\n",
    "# print sniffer.has_header(\n",
    "#     open(\"fruits.csv\").read(sample_bytes))\n",
    "\n",
    "sniffer = csv.Sniffer()\n",
    "with open('/media/ernstboogert/ResearchDat/TLG_E/tsv/tlg0031-001.tsv', newline='') as csvfile:\n",
    "    test_piece = csvfile.read(300)\n",
    "    csvfile.seek(0)\n",
    "    first_line = next(csvfile)\n",
    "#     print(first_line)\n",
    "#     print(len(first_line))\n",
    "    # Define dialect\n",
    "    dialect = sniffer.sniff(test_piece)\n",
    "    print(dialect)\n",
    "    # Automatically define the presence of a header, if header == None\n",
    "    if header == None:\n",
    "        header = sniffer.has_header(test_piece)\n",
    "        print(f'header = {header}')\n",
    "#     first_line = next(test_piece)\n",
    "    data = csv.reader(csvfile, dialect)\n",
    "#     for row in data:\n",
    "#         print(row)\n",
    "#     print(next(data))\n",
    "    csvfile.seek(0)\n",
    "    print(next(data))\n",
    "    print('block')\n",
    "    csvfile.seek(0)\n",
    "    for row in data:\n",
    "        print(row)\n",
    "\n",
    "\n",
    "#     sniffer = csv.Sniffer()\n",
    "#     sample_bytes = 1024\n",
    "#     print(sniffer.has_header(csvfile.read(1024)))\n",
    "#     dialect = csv.Sniffer().sniff(csvfile.read(1024))\n",
    "#     if header == None:\n",
    "#         try:\n",
    "#             header = csv.Sniffer().has_header(csvfile.read(2048))\n",
    "#             print(header)\n",
    "#             csvfile.seek(0)\n",
    "#         except:\n",
    "#             header = False\n",
    "#         print(header)\n",
    "#     data = csv.reader(csvfile, dialect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
