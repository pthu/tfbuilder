{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, glob\n",
    "from copy import copy, deepcopy\n",
    "from os import path\n",
    "from pprint import pprint\n",
    "from collections import OrderedDict\n",
    "from ordered_set import OrderedSet\n",
    "from lxml import etree\n",
    "\n",
    "# fullSub  = re.compile(r'<(note|fw|num).+?</(note|fw|num)>')\n",
    "# wordSub = re.compile(r'</*w>|<w [^>]*?>')\n",
    "# elemSub  = re.compile(r'</*(div|pb|pc|cb|hi|supplied|unclear|seg|ex|space)[^/>]*?/*>')\n",
    "# lbYesSub = re.compile(r'</*lb[^/>]*?/*>')\n",
    "# lbNoSub  = re.compile(r'<lb [^>]*?break=\"no\"[^/>]*?/*>')\n",
    "# gabSub   = re.compile(r'<gap.*?/>')\n",
    "# # partSub  = re.compile(r'<ab[^>]+?part[^>]*?>')\n",
    "ampSub   = re.compile(r'&[^ ]+?;')\n",
    "spaceSub = re.compile(r'\\s*  \\s*')\n",
    "abRE = re.compile(r'<ab n= *\" *(\\w+?) *\"[^>]*>')\n",
    "\n",
    "\n",
    "# hands = set()\n",
    "textElems = set()\n",
    "nontextElems = set()\n",
    "\n",
    "# XML parser\n",
    "# parser = etree.XMLParser(recover=True, strip_cdata=True)\n",
    "parser = etree.XMLParser(recover=True, huge_tree=True, compact=False, remove_pis=True, strip_cdata=True)\n",
    "\n",
    "# XML namespaces\n",
    "NS1 = '{http://www.tei-c.org/ns/1.0}'\n",
    "NS2 = '{http://www.w3.org/XML/1998/namespace}'\n",
    "\n",
    "# XML tags to be preserved\n",
    "DELETE = {\n",
    " '{http://www.tei-c.org/ns/1.0}abbr',\n",
    " '{http://www.tei-c.org/ns/1.0}cb',\n",
    " '{http://www.tei-c.org/ns/1.0}div',\n",
    " '{http://www.tei-c.org/ns/1.0}ex',\n",
    " '{http://www.tei-c.org/ns/1.0}handshift',\n",
    " '{http://www.tei-c.org/ns/1.0}hi',\n",
    " '{http://www.tei-c.org/ns/1.0}num',\n",
    " '{http://www.tei-c.org/ns/1.0}pb',\n",
    " '{http://www.tei-c.org/ns/1.0}pc',\n",
    " '{http://www.tei-c.org/ns/1.0}seg',\n",
    " '{http://www.tei-c.org/ns/1.0}space',\n",
    " '{http://www.tei-c.org/ns/1.0}supplied',\n",
    " '{http://www.tei-c.org/ns/1.0}unclear',\n",
    " '{http://www.tei-c.org/ns/1.0}w',\n",
    "}\n",
    "\n",
    "DELETE_full = {\n",
    " '{http://www.tei-c.org/ns/1.0}fw',\n",
    " '{http://www.tei-c.org/ns/1.0}note',\n",
    "}\n",
    "\n",
    "CHANGE = {\n",
    " '{http://www.tei-c.org/ns/1.0}rgd',\n",
    " '{http://www.tei-c.org/ns/1.0}lb',\n",
    " '{http://www.tei-c.org/ns/1.0}lbP48vyC1L-P13',\n",
    " '{http://www.tei-c.org/ns/1.0}lbP49vyC1L-P13',\n",
    " '{http://www.tei-c.org/ns/1.0}lbP50vyC4L-P13',\n",
    " '{http://www.tei-c.org/ns/1.0}lbP63vyC1L-P13',\n",
    " '{http://www.tei-c.org/ns/1.0}lbP64vyC1L-P13',\n",
    " '{http://www.tei-c.org/ns/1.0}gap',\n",
    "}\n",
    "\n",
    "def mss_clean(input_file, output_path, show_body_elements=False):\n",
    "    # Construct filename\n",
    "    file_path = path.splitext(input_file)[0].split('/')\n",
    "    filename = file_path[-1]\n",
    "    institution = file_path[-3]\n",
    "    if len(filename) == 5 and not filename.endswith('S'):\n",
    "        if filename.startswith('1'):\n",
    "            filename = 'P' + filename[1:].lstrip('0')\n",
    "        elif filename.startswith('2'):\n",
    "            filename = '0' + filename[1:].lstrip('0')\n",
    "        elif filename.startswith('3'):\n",
    "            filename = filename[1:].lstrip('0')\n",
    "        elif filename.startswith('4'):\n",
    "            filename = 'L' + filename[1:].lstrip('0')\n",
    "    if institution == 'Birmingham':\n",
    "        filename = 'B_' + filename\n",
    "    elif institution == 'Muenster':\n",
    "        filename = 'M_' + filename\n",
    "        \n",
    "    \n",
    "    # Make XML tree\n",
    "    tree = etree.parse(input_file, parser)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Retrieve witnesses\n",
    "    witnesses = [wit.get(f'{NS2}id') for wit in root.findall(f'.//{NS1}witness')]\n",
    "#     print(witnesses)\n",
    "\n",
    "    # Clean tags\n",
    "    for tag in DELETE:\n",
    "        if tag == f'{NS1}w':    \n",
    "        # Birmingham transcriptions get different treatment\n",
    "            if filename.startswith('B_'):\n",
    "                for word in root.findall(f'.//{NS1}w'):\n",
    "                    word.text = word.text + ' '\n",
    "                etree.strip_tags(root.find(f'{NS1}text/{NS1}body'), tag)\n",
    "            else:\n",
    "                etree.strip_tags(root.find(f'{NS1}text/{NS1}body'), tag)\n",
    "        else:\n",
    "            etree.strip_tags(root.find(f'{NS1}text/{NS1}body'), tag)\n",
    "    \n",
    "    # Clean elements\n",
    "    for tag in DELETE_full:\n",
    "        # With this piece of code, you can make visible what will be deleted...\n",
    "#         delete = root.findall(f'.//{tag}')\n",
    "#         for i in delete:\n",
    "#             print(i.text)\n",
    "            \n",
    "        etree.strip_elements(root.find(f'{NS1}text/{NS1}body'), tag, with_tail=False)\n",
    "        \n",
    "    # Change tags/elements\n",
    "    for c in CHANGE:\n",
    "        # Handle line breaks\n",
    "        if c in {f'{NS1}lb',\n",
    "                 f'{NS1}lbP48vyC1L-P13',\n",
    "                 f'{NS1}lbP49vyC1L-P13',\n",
    "                 f'{NS1}lbP50vyC4L-P13',\n",
    "                 f'{NS1}lbP63vyC1L-P13',\n",
    "                 f'{NS1}lbP64vyC1L-P13',}:\n",
    "            # Handle not breaking lb's first\n",
    "            lbs_nobreak = root.findall(f'.//{NS1}lb[@break=\"no\"]')\n",
    "            for lb in lbs_nobreak:\n",
    "                lb.tag = 'lb_nobreak'\n",
    "            # delete nobreaks\n",
    "            etree.strip_tags(root.find(f'{NS1}text/{NS1}body'), 'lb_nobreak')\n",
    "            # Then get rid of the other breaks\n",
    "            lbs = root.findall(f'.//{NS1}lb')\n",
    "            # delete lbs after a space has been passed to .text\n",
    "            for lb in lbs:\n",
    "#                 pass\n",
    "                lb.text = ' '\n",
    "            etree.strip_tags(root.find(f'{NS1}text/{NS1}body'), f'{NS1}lb')\n",
    "            \n",
    "        # Correct misspelling\n",
    "        elif c ==  f'{NS1}rgd':\n",
    "            rgds = root.findall(f'.//{NS1}rgd')\n",
    "            for r in rgds:\n",
    "                r.tag = f'{NS1}rdg'\n",
    "            \n",
    "        # Handle gaps\n",
    "        elif c == f'{NS1}gap':\n",
    "            gaps = root.findall(f'.//{NS1}gap')\n",
    "            for gap in gaps:\n",
    "                gap.text = '###gap###'\n",
    "#             etree.strip_tags(root.find(f'{NS1}text/{NS1}body'), f'{NS1}gap')\n",
    "            \n",
    "    if not witnesses:\n",
    "        xml_string = etree.tostring(tree, encoding='unicode')\n",
    "        out = open(f'{output_path}/{filename}.xml', 'w+')\n",
    "        out.write(xml_string)\n",
    "        out.close()\n",
    "    \n",
    "    else:\n",
    "        addUnknown = False\n",
    "        # Check rdg's without hand, like: <rdg type=\"orig\">\n",
    "        no_hands = root.findall(f'.//{NS1}rdg')\n",
    "        for rdg in no_hands:\n",
    "            if not 'hand' in rdg.attrib:\n",
    "                rdg.attrib['hand'] = 'firsthand'\n",
    "            # Check rdg's with empty hand, like: <rdg type=\"corr\" hand=\"\">\n",
    "            elif rdg.attrib['hand'] == '':\n",
    "                rdg.attrib['hand'] = 'unknown'\n",
    "                if not addUnknown:\n",
    "                    witnesses.append('unknown')\n",
    "                    addUnknown = True\n",
    "        \n",
    "        for wit in witnesses:\n",
    "            # Make for each witness a deepcopy of the tree\n",
    "            wit_tree = deepcopy(tree)\n",
    "            wit_root = wit_tree.getroot()\n",
    "            \n",
    "            # Select in case of variation the correct witness (hand!)\n",
    "            apps = wit_root.findall(f'.//{NS1}app')\n",
    "            for app in apps:\n",
    "                # In case the app contains the present witness (hand)\n",
    "                if app.findall(f'.//{NS1}rdg[@hand=\"{wit}\"]'):\n",
    "                    for rdg in app.iterchildren(tag=f'{NS1}rdg'):\n",
    "                        if not rdg.attrib['hand'] == wit:\n",
    "                            app.remove(rdg)\n",
    "                    # Only keep the last intervention by the witness (hand)\n",
    "                    for rdg in app.iterchildren(tag=f'{NS1}rdg'):\n",
    "                        if not rdg == app[-1]: # Check if it is not the last one, because list object (like app[:-1]) has no iterchildren() method\n",
    "                            app.remove(rdg)\n",
    "                # In case the app does not contain the present witness (hand)\n",
    "                else:\n",
    "                    # Define the doings of the first hand\n",
    "                    firsthand = app.findall(f'.//{NS1}rdg[@hand=\"firsthand\"]')\n",
    "                    # Delete all other hands except the first hand\n",
    "                    for rdg in app.iterchildren(tag=f'{NS1}rdg'):\n",
    "                        if not rdg in firsthand:\n",
    "                            app.remove(rdg)\n",
    "                    # Keep only the last intervention of the first hand\n",
    "                    for rdg in firsthand[:-1]:\n",
    "                        app.remove(rdg)\n",
    "    \n",
    "            # Write xml tree to string for final manipulations\n",
    "            xml_string = etree.tostring(wit_tree, encoding='unicode')\n",
    "    \n",
    "            # Setup mechanism to handle sections\n",
    "            ref_dict = {}\n",
    "            def ab_modifier(ab):\n",
    "                nonlocal ref_dict\n",
    "                ab_split = list(filter(None, re.split(r'[BKV]', re.sub(abRE, r'\\g<1>', ab))))\n",
    "                ab_dict = OrderedDict(zip(('book', 'chapter', 'verse'), ab_split))\n",
    "                diff = OrderedDict( tuple(OrderedSet(ab_dict.items()) - OrderedSet(ref_dict.items()) ))\n",
    "                ref_dict = ab_dict\n",
    "                res = ''\n",
    "                for d in diff:\n",
    "                    res += f'<div type=\"{d}\" n=\"{diff[d]}\">'\n",
    "                return res            \n",
    "\n",
    "            # Apply section substitution\n",
    "            xml_string = re.sub(abRE, lambda m: ab_modifier(m.group(0)), xml_string)\n",
    "\n",
    "            # Final cleanup\n",
    "            xml_string = re.sub(ampSub, '', xml_string)     # Delete html markup\n",
    "            xml_string = re.sub(spaceSub, ' ', xml_string)  # Delete superfluous spaces\n",
    "            xml_string = xml_string.replace('</ab>', '')    # Delete end-tags <ab>\n",
    "            xml_string = xml_string.replace('<ab>', '')\n",
    "            xml_string = xml_string.replace('<ab>', '')\n",
    "            xml_string = xml_string.replace('\\n', '')\n",
    "\n",
    "            if wit == '*':\n",
    "                wit = 'star'\n",
    "            out = open(f'{output_path}/{filename}_{wit}.xml', 'w+')\n",
    "            out.write(xml_string) #.replace('\\n', ''))\n",
    "            out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# file_list = glob.glob(path.expanduser('~/github/pthu/sources/manuscripts/mss_transcriptions/**/*.xml'), recursive=True)\n",
    "# file_list = glob.glob(path.expanduser('~/github/manuscripts/Muenster/mss/*.xml'), recursive=True)\n",
    "file_list = glob.glob(path.expanduser('~/github/manuscripts/Birmingham/John/*.xml'), recursive=True)\n",
    "# file_list = glob.glob(path.expanduser('~/github/manuscripts/Muenster/test_in/*.xml'), recursive=True)\n",
    "\n",
    "# print(file_list)\n",
    "\n",
    "# print(file_list)\n",
    "# pool = Pool()\n",
    "# pool.map(process_file, file_list)\n",
    "# pool.close()\n",
    "# pool.join()\n",
    "for file in file_list:\n",
    "    print(f'Converting {file}...\\n')\n",
    "#     mss_clean(file, path.expanduser('~/github/manuscripts/Muenster/test_out'), show_body_elements=True)\n",
    "#     mss_clean(file, path.expanduser('~/github/manuscripts/Muenster/preprocessed'), show_body_elements=True)\n",
    "    mss_clean(file, path.expanduser('~/github/manuscripts/Birmingham/John_preprocessed'), show_body_elements=True)\n",
    "\n",
    "# print(len(textElems))\n",
    "# pprint(textElems)\n",
    "# print(len(nontextElems))\n",
    "# pprint(nontextElems)\n",
    "# pprint(hands)\n",
    "# mss_clean(path.expanduser(path.join('~/github/pthu/sources/manuscripts/mss_transcriptions/Muenster/majuscules/20011.xml')), path.expanduser(path.join('~/github/pthu/sources/manuscripts/test/out')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import OrderedDict\n",
    "from ordered_set import OrderedSet\n",
    "\n",
    "# ab = '<ab n=\"B04K4V6\">'\n",
    "\n",
    "abRE = re.compile(r'<ab n= *\" *(\\w+?) *\"[^>]*>')\n",
    "\n",
    "test = 'εμπροσθεν εκεινου ·<ab n=\"B04K3V29\"> ο εχων την <ab n=\"B04K4V1\"> νυμφην ·'\n",
    "\n",
    "refs = ['<ab n=\"B04K4V6\">', '<ab n=\"B04K4V7\">', '<ab n=\"B04K4V8\">', '<ab n=\"B04K5V1\">', '<ab n=\"B04K5V2\">']\n",
    "ref_dict = OrderedDict()\n",
    "\n",
    "def ab_modifier(ab):\n",
    "    global ref_dict\n",
    "    ab_split = list(filter(None, re.split(r'[BKV]', re.sub(abRE, r'\\g<1>', ab))))\n",
    "    ab_dict = OrderedDict(zip(('book', 'chapter', 'verse'), ab_split))\n",
    "    diff = OrderedDict( tuple(OrderedSet(ab_dict.items()) - OrderedSet(ref_dict.items()) ))\n",
    "    ref_dict = ab_dict\n",
    "    res = ''\n",
    "    for d in diff:\n",
    "        res += f'<div type=\"{d}\" n=\"{diff[d]}\">'\n",
    "    return res\n",
    "    \n",
    "# for ab in refs:\n",
    "#     print(ab_modifier(ab))\n",
    "#     print(ref_dict)\n",
    "    \n",
    "\n",
    "print(re.sub(abRE, lambda m: ab_modifier(m.group(0)), test))\n",
    "\n",
    "\n",
    "# res = list(filter(None, re.split(r'[BKV]', re.sub(abRE, r'\\g<1>', ab))))\n",
    "# print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "n = 'B27K1V2'\n",
    "\n",
    "# ab_split = list(filter(None, re.split(r'[BKV]', re.sub(abRE, r'\\g<1>', ab))))\n",
    "# ab_dict = OrderedDict(zip(('book', 'chapter', 'verse'), ab_split))\n",
    "\n",
    "re.split(r'[BKV]', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piet = []\n",
    "for i in piet[:-1]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
